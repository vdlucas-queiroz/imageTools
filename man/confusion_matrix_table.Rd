% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/13_confusion_matrix.R
\name{confusion_matrix_table}
\alias{confusion_matrix_table}
\title{Generate Confusion Matrix and Accuracy Metrics from Predictions}
\usage{
confusion_matrix_table(df_temp)
}
\arguments{
\item{df_temp}{A dataframe with at least two columns: `predicted_class` and `Class`,
where `predicted_class` contains the model's predictions and `Class` contains the true class labels.}
}
\value{
A list of data frames, where each data frame represents a different set of metrics:
        overall accuracy, the confusion matrix itself, producer's accuracy, and user's accuracy.
}
\description{
This function takes a dataframe with predicted and actual classes to generate a confusion matrix and calculate
various accuracy metrics. It returns a list containing data frames for overall accuracy, the confusion matrix,
producer's accuracy, and user's accuracy.
}
\details{
The function first creates a confusion matrix using the `confusionMatrix` function from the `caret` package,
comparing the predicted classes against the actual classes. It then calculates the overall accuracy, producer's
accuracy, and user's accuracy from this confusion matrix. Each of these metrics is returned as a separate dataframe
within a list, facilitating further analysis or reporting.
}
\examples{
df_temp <- data.frame(predicted_class = sample(c("A", "B"), 100, replace = TRUE),
                      Class = sample(c("A", "B"), 100, replace = TRUE))
confusion_df <- confusion_matrix_table(df_temp)
print(confusion_df)
}
