% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/13_confusion_matrix.R
\name{metrics_calculation}
\alias{metrics_calculation}
\title{Calculate Evaluation Metrics from Confusion Matrix}
\usage{
metrics_calculation(confusion_matrix)
}
\arguments{
\item{confusion_matrix}{A matrix representing the confusion matrix of the classification results.}
}
\value{
A list containing the overall accuracy, F1 macro score, producers' accuracy, users' accuracy, and F1 scores.
}
\description{
This function calculates evaluation metrics from a confusion matrix, including overall accuracy, F1 macro score, producers' accuracy, users' accuracy, and F1 scores.
}
\examples{
confusion_matrix <- matrix(c(50, 10, 5, 35), nrow = 2, byrow = TRUE)
colnames(confusion_matrix) <- c("Class1", "Class2")
rownames(confusion_matrix) <- c("Class1", "Class2")
result <- metrics_calculation(confusion_matrix)
print(result)
}
